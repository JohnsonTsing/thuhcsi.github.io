## Speech Synthesis

**(Interspeech, August 2021)** VAENAR-TTS: Variational Auto-Encoder based Non-AutoRegressive Text-to-Speech Synthesis
* [paper](https://arxiv.org/abs/2107.03298)
* [code](https://github.com/thuhcsi/VAENAR-TTS)
* [audio samples](https://light1726.github.io/vaenar-tts/)

**(Interspeech, August 2021)** Towards Multi-Scale Style Control for Expressive Speech Synthesis
* [paper](https://arxiv.org/abs/2104.03521)
* [audio samples](https://thuhcsi.github.io/interspeech2021-multi-scale-style-control/)

**(SLT, January 2021)** Controllable Emphatic Speech Synthesis based on Forward Attention for Expressive Speech Synthesis
* [paper](https://ieeexplore.ieee.org/abstract/document/9383537)
* [audio samples](https://thuhcsi.github.io/slt2021-controllable-emphasis-tts/)

**(ICASSP, June 2021)** Syntactic Representation Learning for Neural Network based TTS with Syntactic Parse Tree Traversal
* [paper](https://ieeexplore.ieee.org/abstract/document/9414671)
* [audio samples](https://thuhcsi.github.io/icassp2021-tree-tts/)

**(ICASSP, June 2021)** Emotion Controllable Speech Synthesis using Emotion-Unlabeled Dataset with the Assistance of Cross-Domain Speech Emotion Recognition
* [paper](https://ieeexplore.ieee.org/abstract/document/9413907)
* [code](https://github.com/thuhcsi/icassp2021-emotion-tts)
* [audio samples 1](https://thuhcsi.github.io/icassp2021-emotion-tts/emo4cls_demo.html)
* [audio samples 2](https://thuhcsi.github.io/icassp2021-emotion-tts/emo2d_demo.html)

**(Interspeech, October 2020)** Enhancing Monotonicity for Robust Autoregressive Transformer TTS
* [paper](https://www.isca-speech.org/archive/Interspeech_2020/pdfs/1751.pdf)
* [audio samples](https://thuhcsi.github.io/interspeech2020-monotonicity-transformer-tts/)

**(Interspeech, September 2019)** Knowledge-based Linguistic Encoding for End-to-End Mandarin Text-to-Speech Synthesis
* [paper](https://www.isca-speech.org/archive/Interspeech_2019/pdfs/1118.pdf)
* [audio samples](https://thuhcsi.github.io/interspeech2019-tts-samples/)

**(ICASSP, April 2019)** Quasi-Fully Convolutional Neural Network with Variational Inference for Speech Synthesis
* [paper](https://ieeexplore.ieee.org/abstract/document/8682528)
* [audio samples](https://mu94w.github.io/QFCVI/)

## Voice Converstion

**(Interspeech, August 2021)** Adversarially Learning Disentangled Speech Representations for Robust Multi-factor Voice Conversion
* [paper](https://arxiv.org/abs/2102.00184)
* [audio samples](https://thuhcsi.github.io/interspeech2021-multi-factor-vc/)

**(Interspeech, September 2019)** One-shot Voice Conversion with Global Speaker Embeddings
* [paper](https://isca-speech.org/archive/Interspeech_2019/pdfs/2365.pdf)
* [audio samples](https://daidongyang.github.io/vc-eval/)

**(ICASSP, April 2019)** A Compact Framework for Voice Conversion using Wavenet Conditioned on Phonetic Posteriorgrams
* [paper](https://ieeexplore.ieee.org/abstract/document/8682938)
* [audio samples](https://light1726.github.io/voice_conversion_demo/)

## Speaker Verification

**(Interspeech, August 2021)** Voting for the Right Answer: Adversarial Defense for Speaker Verification
* [paper](https://arxiv.org/abs/2106.07868)
* [code](https://github.com/thuhcsi/adsv_voting)

## Emotion Recognition

**(IJCAI, August 2019)** Towards Discriminative Representation Learning for Speech Emotion Recognition
* [paper](https://www.ijcai.org/proceedings/2019/0703.pdf)
* [code](https://github.com/thuhcsi/IJCAI2019-DRL4SER)
